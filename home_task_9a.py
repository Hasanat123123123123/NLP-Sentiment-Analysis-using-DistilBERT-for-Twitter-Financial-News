# -*- coding: utf-8 -*-
"""Home_task_9A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11ogFKS7Y2QsMvxAREPqKN7CuAXOsg-o_
"""

!pip install torch torchvision torchaudio pytorch-lightning transformers datasets

pip install transformers datasets torch sklearn

import torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments
)
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# Check if GPU is available and set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Load the dataset
dataset = load_dataset("zeroshot/twitter-financial-news-sentiment", cache_dir="./CentralCache")

# Tokenize the dataset
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased", cache_dir="./CentralCache")

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_dataset = dataset.map(tokenize_function, batched=True)

# Split dataset into training and validation using Hugging Face's train_test_split
split_dataset = tokenized_dataset["train"].train_test_split(test_size=0.2, seed=42)

# Assign training and validation datasets
train_dataset = split_dataset["train"]
val_dataset = split_dataset["test"]

# Load the model
model = AutoModelForSequenceClassification.from_pretrained(
    "distilbert-base-uncased", num_labels=3, cache_dir="./CentralCache"
)

# Define training arguments
training_args = TrainingArguments(
    output_dir="./results",          # Output directory
    evaluation_strategy="epoch",    # Evaluate at the end of each epoch
    learning_rate=2e-5,             # Learning rate
    per_device_train_batch_size=16, # Batch size for training
    per_device_eval_batch_size=16,  # Batch size for evaluation
    num_train_epochs=5,             # Number of epochs
    weight_decay=0.01,              # Weight decay
    logging_dir="./logs",           # Directory for storing logs
    save_total_limit=1,             # Limit the number of saved checkpoints
    logging_steps=10,               # Log every 10 steps
    push_to_hub=False,              # Do not push to Hugging Face Hub
)

# Define metrics for evaluation
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = torch.argmax(torch.tensor(logits), axis=-1).numpy()
    labels = torch.tensor(labels).numpy()
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average="weighted")
    acc = accuracy_score(labels, predictions)
    return {"accuracy": acc, "f1": f1, "precision": precision, "recall": recall}

# Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

# Evaluate the model
trainer.evaluate()

# Example prediction function
def predict_sentiment(tweets):
    inputs = tokenizer(tweets, padding=True, truncation=True, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = model(**inputs)
    predictions = torch.argmax(outputs.logits, dim=1)
    sentiment_labels = ["Bearish", "Bullish", "Neutral"]
    return [sentiment_labels[pred.item()] for pred in predictions]

# Example usage for prediction
new_tweets = [
    "The market is looking bullish today!",
    "I believe the stocks will go down.",
    "This news seems neutral with no major impact."
]

predicted_sentiments = predict_sentiment(new_tweets)
print(predicted_sentiments)

# Save the model and tokenizer
model.save_pretrained("./financial_sentiment_model")
tokenizer.save_pretrained("./financial_sentiment_model")

print("Model and tokenizer saved to ./financial_sentiment_model")

!pip install transformers gradio

import gradio as gr
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Load the saved model and tokenizer
model_save_path = "./financial_sentiment_model"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load model and tokenizer, move model to the appropriate device
model = AutoModelForSequenceClassification.from_pretrained(model_save_path).to(device)
tokenizer = AutoTokenizer.from_pretrained(model_save_path)

# Define the prediction function
def predict_sentiment(tweet):
    # Tokenize the input tweet
    inputs = tokenizer(tweet, padding=True, truncation=True, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = model(**inputs)

    # Get the predicted class
    predictions = torch.argmax(outputs.logits, dim=1)
    sentiment_labels = ["Bearish", "Bullish", "Neutral"]
    return sentiment_labels[predictions.item()]

# Create the Gradio interface
def classify_text(input_text):
    # Make prediction for the input text
    prediction = predict_sentiment(input_text)
    return prediction

# Define the Gradio layout
with gr.Blocks() as demo:
    gr.Markdown("# Financial Sentiment Analysis")
    gr.Markdown("Input a tweet to predict whether it is **Bullish**, **Bearish**, or **Neutral**.")

    with gr.Row():
        input_box = gr.Textbox(
            label="Enter Tweet",
            placeholder="Type your tweet here..."
        )
        output_box = gr.Textbox(
            label="Predicted Sentiment",
            interactive=False
        )

    classify_button = gr.Button("Classify")
    classify_button.click(fn=classify_text, inputs=input_box, outputs=output_box)

# Launch the interface
demo.launch()